---
title: "Firearm Violence and ICE-race/income in New York, NY"
author: "Adam Whalen"
date: "6/26/2024"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(httr)
library(leaflet)
library(tidygeocoder)
library(tidycensus)

# register with my Census API key (note that this step may not be needed):
# census_api_key("68f4696702f9089f4ec32841b66e6d8f0d5febe1", install = TRUE)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### NYC OpenData

This research project will be an analysis of firearm violence within the five boroughs of New York, NY. I obtained data from [NYC OpenData](https://data.cityofnewyork.us/Public-Safety/NYPD-Shooting-Incident-Data-Historic-/833y-fsy8/about_data), a city-run repository of publicly-available datasets from various agencies. I will be examining the association between firearm violence in New York with the Index of Concentration at the Extremes, a measure of racial and economic inequality, at the Census tract level. NYC Firearm data was accessed June 25, 2024 and was last updated on April 23, 2024. Firearm violence data runs from 2006 until the end of 2023. 

First, read in the NYC data.

```{r fav_import, warning = F}
nyc_fav = read_csv("./data/NYPD_Shooting_Incident_Data__Historic__20240625.csv") %>% 
  janitor::clean_names()
```

The dataset contains a lot of information that is not necessary for our use, as well as some indicators that are still in development, so we will tidy the set and exclude them.

```{r tidy_restrict}
fav_tidy = 
  nyc_fav %>% 
  rename(fatal = statistical_murder_flag) %>% 
  mutate(
    incident_key = as.character(incident_key),
    occur_date = as.Date(occur_date, "%m/%d/%Y"),
    boro = as_factor(boro),
    vic_age_group = as_factor(vic_age_group),
    vic_sex = as_factor(vic_sex),
    vic_race = as_factor(vic_race)
  ) %>% 
  select(incident_key, occur_date, boro, fatal, vic_age_group:vic_race, latitude, longitude)
```

Some quick summary statistics of the people who were victims of firearm violence in New York:

```{r summary}
fav_tidy %>% 
  group_by(vic_race) %>% 
  count()

fav_tidy %>% 
  group_by(vic_age_group) %>% 
  count()

fav_tidy %>% 
  group_by(vic_sex) %>% 
  count()

fav_tidy %>% 
  group_by(boro) %>% 
  count()

fav_tidy %>% 
  group_by(fatal) %>% 
  count()
```

The majority of firearm victims in New York were Black or Hispanic, between the ages of 18 and 45, male, located in Brooklyn, and survived their gunshot wound. 

Let's now look at the spatial distribution of the data quickly, as a gut check for accuracy/data prep.

```{r geoplot}
fav_tidy %>% 
  mutate(text_label = str_c(occur_date, " \n", fatal)) %>% 
  leaflet() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addCircleMarkers(lat = ~latitude, lng = ~longitude, radius = 0.1, label = ~text_label)
```

I will need to aggregate these up to the CT-level in order to merge with ICE data and run analyses, or at least assign a CT value to each case.


### US Census data for Index of Concentration at the Extremes

Often, geospatial measures of inequality examine only income or race/ethnicity independently. The Index of Concentration at the Extremes (ICE) allows us to examine both simultaneously, and provides a relative measure of the amount of racialized economic segregation for a specific spatial area. For example, we can examine whether gun violence is more common in whiter, wealthier CTs compared to less white, lower income CTs. 

NOTE: which estimate to pull? Is it better to just grab one (most recent? median?) estimates and use that as a covariate, or should I grab periodic measures and allow it to vary over time? Or, use 2010 Census data as it represents a midpoint that could be extrapolated forwards and backwards in time? Or is there another mechanism? Should talk about this with someone smarter. 

Because our exposure data spans 2006-2023, for ease I will use the 2015 US Census ACS 5-year estimates (2011-2015) to calculate ICE measures. We may also want to look at additional covariates, but this will be good for now. 

I also will examine ICE-income (income inequality alone), ICE-race (racial inequality alone), and CT-level % in poverty to see how the association with firearm violence rates differs with each measure. 

Much of this code and approach has been borrowed from the [PHDGP 2.0](https://www.hsph.harvard.edu/thegeocodingproject/the-public-health-disparities-geocoding-project-2-0/) developed by Chen, Krieger, et al at Harvard. 

NOTE: should we adjust for county (boro)-level covariates? Should probably at least pull that out for random effects?

```{r acs}
# identify and select the variables we need from ACS
var_acs =
  tibble::tribble(
  ~var, ~varname, ~description,
  # total population
  "B01001_001",  "total_popsize", "total population estimate", 
  
  # racial composition 
  "B02001_001",  "race_ethnicity_total", "race_ethnicity_total",
  "B03001_003",  'total_hispanic',           'total hispanic population estimate',
  "B02001_003",  'total_black',              'total black, hispanic or non-hispanic estimate',
  "B02001_002",  'total_white_nh',           'total white, non-hispanic population estimate',
  
  # ICEraceinc
  "B19001_001",  'hhinc_total',   "total population for household income estimates",
  "B19001A_002",  'hhinc_w_1',     "white n.h. pop with household income <$10k",
  "B19001A_003",  'hhinc_w_2',     "white n.h. pop with household income $10k-14 999k",
  "B19001A_004",  'hhinc_w_3',     "white n.h. pop with household income $15k-19 999k",
  "B19001A_005",  'hhinc_w_4',     "white n.h. pop with household income $20k-24 999k",
  "B19001A_014",  'hhinc_w_5',     "white n.h. pop with household income $100 000 to $124 999",
  "B19001A_015",  'hhinc_w_6',     "white n.h. pop with household income $125k-149 999k",
  "B19001A_016",  'hhinc_w_7',     "white n.h. pop with household income $150k-199 999k",
  "B19001A_017",  'hhinc_w_8',     "white n.h. pop with household income $196k+",
  "B19001_002",  'hhinc_total_1', "total pop with household income <$10k",
  "B19001_003",  'hhinc_total_2', "total pop with household income $10k-14 999k",
  "B19001_004",  'hhinc_total_3', "total pop with household income $15k-19 999k",
  "B19001_005",  'hhinc_total_4', "total pop with household income $20k-24 999k",
  "B19001_014",  'hhinc_total_5', "total pop with household income $100 000 to $124 999",
  "B19001_015",  'hhinc_total_6', "total pop with household income $125k-149 999k",
  "B19001_016",  'hhinc_total_7', "total pop with household income $150k-199 999k",
  "B19001_017",  'hhinc_total_8', "total pop with household income $196k+",

  # poverty
  "B05010_002",  'in_poverty',    "population with household income < poverty line",
  "B05010_001",  'total_pop_for_poverty_estimates',  "total population for poverty estimates"
  )

# pull the ACS variables 
acs15 = get_acs(
  geography = 'tract',
  state = 'NY',
  county = c("New York", "Queens", "Bronx", "Richmond", "Kings"),
  year = 2015,
  variables = var_acs$var)

# pivot to a wide format for renaming, dropping the margin of error data
acs15 %<>% 
  select(-moe) %>% 
  pivot_wider(names_from = variable, values_from = estimate)

# rename the columns using our rename_vars
# 
# first we create a named vector, rename_vars, which has elements that are the
# acs variables we request and convenient, human readable names.
# 
# then we use rename_vars with the rename function from dplyr. 
# typically the rename function takes a syntax as follows: 
#   data %>% rename(oldname1 = newname1, oldname2 = newname2, ...)
# but in our case, we already have a named vector (rename_vars) that we 
# want to use, and so to use the rename_vars named vector inside rename
# we use the injection-operator `!!`.  you can learn more about the injection
# operator by running ?`!!` in your R console. 

rename_vars = setNames(var_acs$var, var_acs$varname)
acs15 = acs15 %>% rename(!!rename_vars)

# calculate ABSMs
acs15_ice = 
  acs15 %>%
  mutate(
    # we calculate the people of color low income counts as the overall
    # low income counts minus the white non-hispanic low income counts
    nonwhite_low_income =
      (hhinc_total_1 + hhinc_total_2 + hhinc_total_3 + hhinc_total_4) -
      (hhinc_w_1 + hhinc_w_2 + hhinc_w_3 + hhinc_w_4),
    # sum up the white non-hispanic high income counts
    whitenh_high_income =
      (hhinc_w_5 + hhinc_w_6 + hhinc_w_7 + hhinc_w_8),
    # calculate the index of concentration at the extremes for racialized
    # economic segregation (high income white non-hispanic vs. low income
    # people of color)
    ICEraceinc =
      (whitenh_high_income - nonwhite_low_income) /
      hhinc_total,

    prop_in_poverty = in_poverty / total_pop_for_poverty_estimates,
    # ICE race - prop nonwhite to prop white
    ICErace = 
      (total_white_nh - (total_popsize - total_white_nh)) / total_popsize,
    
    # ICE income: prop low income to high income
    low_inc = (hhinc_total_1 + hhinc_total_2 + hhinc_total_3 + hhinc_total_4),
    high_inc = (hhinc_total_5 + hhinc_total_6 + hhinc_total_7 + hhinc_total_8),
    ICEincome = (high_inc - low_inc) / total_popsize,
    
    prop_black = total_black / total_popsize,
    prop_hispanic = total_hispanic / total_popsize,
    prop_white_nh = total_white_nh / total_popsize
    ) %>%
  select(
    GEOID,
    NAME,
    ICEraceinc,
    prop_in_poverty,
    ICErace,
    ICEincome,
    prop_black,
    prop_hispanic,
    prop_white_nh,
    total_popsize
  )
```

Pause here as of 7/12/24.

Temporary change in analytic plan: write to CSV and do simple spatial regression analysis in QGIS. 

```{r write_temp, eval = F}
acs15_ice %>% write_csv("./data/acs_data.csv")
fav_tidy %>% write_csv("./data/nyc_fav.csv")
```


Need to assess how to format FAV data so that it can be used in the same dataset as the ICE data and be applied to a Poisson model. Current thought is to assign CTs to each case and calculate IRRs for quartiles of ICE. 

```{r eval = F}
# join in the ABSMs data
uninsurance %<>% left_join(
  select(
    absms,
    GEOID,
    ICEraceinc,
    prop_in_poverty,
    median_income,
    crowding,
    prop_black,
    prop_hispanic,
    prop_white_nh
  ),
  by = c('geoid' = 'GEOID')
)

# add quantile cutpoints to ICEraceinc
ICEraceinc_cutpoints <- Hmisc::wtd.quantile(uninsurance$ICEraceinc,
                                            weights = uninsurance$estimate_total_19_64_population,
                                            probs = seq(0,1,.2))
uninsurance %<>% mutate(
  ICEraceinc_cut = cut(ICEraceinc, ICEraceinc_cutpoints, include.lowest = TRUE))

# reverse the factor ordering so the most advantaged group is the reference category
uninsurance$ICEraceinc_cut %<>% forcats::fct_rev()

# add cutpoints to pct in poverty
uninsurance %<>% mutate(
  poverty_cut = cut(
    prop_in_poverty, 
    c(0,.05,.1,.15,.2,1),
    include.lowest=TRUE
  )
)

# add cutpoints to median income
median_income_cutpoints <- Hmisc::wtd.quantile(uninsurance$median_income,
                                               weights = uninsurance$total_popsize,
                                               probs = seq(0,1,.2))
uninsurance %<>% mutate(
  median_income_cut = cut(
    median_income, 
    median_income_cutpoints,
    include.lowest=TRUE
  )
)
uninsurance$median_income_cut %<>% forcats::fct_rev()

# add cutpoints to crowding
crowding_cutpoints <- Hmisc::wtd.quantile(uninsurance$crowding,
                                               weights = uninsurance$total_popsize,
                                               probs = seq(0,1,.2))
uninsurance %<>% mutate(
  crowding_cut = cut(
    crowding, 
    crowding_cutpoints,
    include.lowest=TRUE
  )
)


# add cutpoints to proportion black
prop_black_cutpoints <- Hmisc::wtd.quantile(uninsurance$prop_black,
                                               weights = uninsurance$total_popsize,
                                               probs = seq(0,1,.2))
uninsurance %<>% mutate(
  prop_black_cut = cut(
    prop_black, 
    prop_black_cutpoints,
    include.lowest=TRUE
  )
)

# add cutpoints to proportion hispanic
prop_hispanic_cutpoints <- Hmisc::wtd.quantile(uninsurance$prop_hispanic,
                                               weights = uninsurance$total_popsize,
                                               probs = seq(0,1,.2))
uninsurance %<>% mutate(
  prop_hispanic_cut = cut(
    prop_hispanic, 
    prop_hispanic_cutpoints,
    include.lowest=TRUE
  )
)

# add cutpoints to proportion white
prop_white_nh_cutpoints <- Hmisc::wtd.quantile(uninsurance$prop_white_nh,
                                               weights = uninsurance$total_popsize,
                                               probs = seq(0,1,.2))
uninsurance %<>% mutate(
  prop_white_nh_cut = cut(
    prop_white_nh, 
    prop_white_nh_cutpoints,
    include.lowest=TRUE
  )
)
```



```{r acs_basic, eval = F}


acs = 
  load_variables(2018, "acs5", cache = TRUE)

vars = c(Total = "B01001_001",
         Poverty = "B06012_002",
         No_Ins = "B992701_003",
         White = "B02001_002",
         Unemp = "B27011_008")

data = get_acs(state = "ny", 
               geography = "tract",
               variables = vars,
               geometry = TRUE,
               survey = "acs5",
               output = "wide")
nys_demog = 
  data %>% 
  mutate(
    pct_poverty = (PovertyE/TotalE) * 100,
    pct_insured = (No_InsE/TotalE) * 100,
    pct_white = (WhiteE/TotalE) * 100,
    pct_unemp = (UnempE/TotalE) * 100
  ) %>% 
  select(GEOID, NAME, geometry, pct_poverty:pct_unemp)

plot(nys_demog)
```

Looks good. Now, let's remove the geography and export to be used in QGIS.

```{r write, eval = F}
nys_demog %>% 
  select(-geometry) %>% 
  write_csv("./data/nys_demog.csv")
```


